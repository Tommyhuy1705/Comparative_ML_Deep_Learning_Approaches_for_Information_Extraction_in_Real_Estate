{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a32b81",
   "metadata": {},
   "source": [
    "# Benchmark (Deep Learning) — NER / RE\n",
    "\n",
    "Notebook này chỉ đánh giá bằng:\n",
    "- `classification_report`,\n",
    "- ma trận nhầm lẫn (confusion matrix).\n",
    "\n",
    "Ghi chú:\n",
    "- NER đánh giá ở mức **token** (lọc bỏ token nhãn `-100`).\n",
    "- RE đánh giá ở mức **sample**.\n",
    "- Tiền xử lý bám theo `src/data_loader/dataset.py` (PhoBERT tokenizer, `is_split_into_words=True` cho NER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294486aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizerFast\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.data_loader.dataset import (\n",
    "    convert_label_studio_to_ner_data,\n",
    "    prepare_re_data_from_json,\n",
    "    NERDataset,\n",
    "    REDataset,\n",
    "),\n",
    "from src.models.deep_learning import PhoBertForNER, PhoBertForRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Paths =====\n",
    "ROOT = Path('..').resolve()\n",
    "DATA_DIR = ROOT / 'data' / '04_model_input'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "\n",
    "TEST_JSON_PATH = DATA_DIR / 'test_dataset.json'\n",
    "TRAIN_JSON_PATH = DATA_DIR / 'train_dataset.json' \n",
    "\n",
    "NER_ID2LABEL_PATH = MODELS_DIR / 'ner' / 'ner_id2label.json'\n",
    "RE_ID2LABEL_PATH  = MODELS_DIR / 're' / 're_id2label.json'\n",
    "\n",
    "# Optional: đặt weight đã train vào đây (nếu có)\n",
    "NER_WEIGHTS_CANDIDATES = [\n",
    "\n",
    "]\n",
    "RE_WEIGHTS_CANDIDATES = [\n",
    "\n",
    "]\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('TEST_JSON_PATH:', TEST_JSON_PATH)\n",
    "print('TEST_JSON_PATH exists:', TEST_JSON_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Load raw JSON =====\n",
    "with open(TEST_JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "train_json = None\n",
    "if TRAIN_JSON_PATH.exists():\n",
    "    with open(TRAIN_JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        train_json = json.load(f)\n",
    "\n",
    "print('Test docs :', len(test_json))\n",
    "print('Train docs:', 0 if train_json is None else len(train_json))\n",
    "\n",
    "# ===== Tokenizer =====\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('vinai/phobert-base-v2', add_prefix_space=True)\n",
    "print('Tokenizer loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_id2label(path: Path, fallback: str):\n",
    "    if path.exists():\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            raw = json.load(f)\n",
    "        return {int(k): v for k, v in raw.items()}\n",
    "\n",
    "    if train_json is None:\n",
    "        raise FileNotFoundError(f'Missing {path} and no train json to recreate mapping')\n",
    "\n",
    "    if fallback == 'ner':\n",
    "        ner_data_raw = convert_label_studio_to_ner_data(train_json)\n",
    "        labels = sorted({lab for sent in ner_data_raw for _, lab in sent})\n",
    "        return {i: lab for i, lab in enumerate(labels)}\n",
    "    if fallback == 're':\n",
    "        re_data_raw = prepare_re_data_from_json(train_json)\n",
    "        labels = sorted({item['label'] for item in re_data_raw})\n",
    "        return {i: lab for i, lab in enumerate(labels)}\n",
    "    raise ValueError('fallback must be ner|re')\n",
    "\n",
    "def id2label_to_label2id(id2label):\n",
    "    return {v: k for k, v in id2label.items()}\n",
    "\n",
    "ner_id2label = load_id2label(NER_ID2LABEL_PATH, fallback='ner')\n",
    "re_id2label  = load_id2label(RE_ID2LABEL_PATH,  fallback='re')\n",
    "ner_label2id = id2label_to_label2id(ner_id2label)\n",
    "re_label2id  = id2label_to_label2id(re_id2label)\n",
    "\n",
    "print('NER labels:', len(ner_id2label))\n",
    "print('RE labels :', len(re_id2label))\n",
    "\n",
    "# ===== Prepare datasets =====\n",
    "ner_test_data = convert_label_studio_to_ner_data(test_json)\n",
    "re_test_data  = prepare_re_data_from_json(test_json)\n",
    "\n",
    "ner_test_ds = NERDataset(ner_test_data, tokenizer=tokenizer, label2id=ner_label2id, max_len=256)\n",
    "re_test_ds  = REDataset(re_test_data,  tokenizer=tokenizer, label2id=re_label2id,  max_len=256)\n",
    "\n",
    "ner_test_loader = DataLoader(ner_test_ds, batch_size=8, shuffle=False)\n",
    "re_test_loader  = DataLoader(re_test_ds,  batch_size=16, shuffle=False)\n",
    "\n",
    "print('NER test sentences:', len(ner_test_ds))\n",
    "print('RE test pairs     :', len(re_test_ds))\n",
    "\n",
    "def find_first_existing(candidates):\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def require_weights(model, candidates, model_name: str):\n",
    "    p = find_first_existing(candidates)\n",
    "    if p is None:\n",
    "        raise FileNotFoundError(\n",
    "            f'Không tìm thấy weight đã lưu cho {model_name}.\\n'\n",
    "            'Hãy copy file weight vào một trong các path sau rồi chạy lại:\\n'\n",
    "            + '\\n'.join([f' - {c}' for c in candidates])\n",
    "        )\n",
    "    state = torch.load(p, map_location='cpu')\n",
    "    if isinstance(state, dict) and 'state_dict' in state:\n",
    "        state = state['state_dict']\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    print(f'Loaded {model_name} weights:', p)\n",
    "    return p\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d356e48",
   "metadata": {},
   "source": [
    "## NER (PhoBERT) — classification report & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006493ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = PhoBertForNER('vinai/phobert-base-v2', num_labels=len(ner_id2label))\n",
    "_ = require_weights(ner_model, NER_WEIGHTS_CANDIDATES, model_name='NER')\n",
    "ner_model.to(DEVICE)\n",
    "ner_model.eval()\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in ner_test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "        logits = ner_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(logits, dim=2).cpu().numpy()\n",
    "\n",
    "        # Flatten + filter ignore_index (-100)\n",
    "        for i in range(labels.shape[0]):\n",
    "            for j in range(labels.shape[1]):\n",
    "                if labels[i, j] == -100:\n",
    "                    continue\n",
    "                all_true.append(ner_id2label[int(labels[i, j])])\n",
    "                all_pred.append(ner_id2label[int(preds[i, j])])\n",
    "\n",
    "labels_sorted = [ner_id2label[i] for i in sorted(ner_id2label.keys())]\n",
    "print(classification_report(all_true, all_pred, labels=labels_sorted, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(all_true, all_pred, labels=labels_sorted)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=labels_sorted, yticklabels=labels_sorted)\n",
    "plt.title('NER Confusion Matrix (token-level)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f51cd",
   "metadata": {},
   "source": [
    "## RE (PhoBERT) — classification report & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_model = PhoBertForRE('vinai/phobert-base-v2', num_labels=len(re_id2label))\n",
    "_ = require_weights(re_model, RE_WEIGHTS_CANDIDATES, model_name='RE')\n",
    "re_model.to(DEVICE)\n",
    "re_model.eval()\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in re_test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "        logits = re_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        all_true.extend([re_id2label[int(x)] for x in labels])\n",
    "        all_pred.extend([re_id2label[int(x)] for x in preds])\n",
    "\n",
    "labels_sorted = [re_id2label[i] for i in sorted(re_id2label.keys())]\n",
    "print(classification_report(all_true, all_pred, labels=labels_sorted, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(all_true, all_pred, labels=labels_sorted)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_sorted, yticklabels=labels_sorted)\n",
    "plt.title('RE Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
