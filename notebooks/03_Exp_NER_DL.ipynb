{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f854167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyvi transformers seqeval evaluate google-cloud-bigquery-storage protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a17b0",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "import itertools\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict \n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModel, RobertaTokenizerFast\n",
    "from transformers import AutoModelForTokenClassification, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from seqeval.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69441aa7",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924295a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data files...\")\n",
    "TRAIN_PATH = '../data/04_model_input/train_dataset.json'\n",
    "TEST_PATH = '../data/04_model_input/test_dataset.json'\n",
    "DEV_PATH = '../data/04_model_input/dev_dataset.json'\n",
    "\n",
    "with open(TRAIN_PATH, 'r', encoding='utf-8') as f:\n",
    "    train_json = json.load(f)\n",
    "\n",
    "with open(TEST_PATH, 'r', encoding='utf-8') as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "with open(DEV_PATH, 'r', encoding='utf-8') as f:\n",
    "    dev_json = json.load(f)\n",
    "\n",
    "print(f\"-> Train raw docs: {len(train_json)}\")\n",
    "print(f\"-> Test raw docs: {len(test_json)}\")\n",
    "print(f\"-> Dev raw docs: {len(dev_json)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e97dca",
   "metadata": {},
   "source": [
    "## Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb95750",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    add_prefix_space=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a7106",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_pyvi_offsets(text):\n",
    "    tokenized_text = ViTokenizer.tokenize(text)\n",
    "    raw_tokens = tokenized_text.split()\n",
    "    \n",
    "    tokens_map = []\n",
    "    cursor = 0\n",
    "    \n",
    "    for token in raw_tokens:\n",
    "        search_token = token.replace(\"_\", \" \")\n",
    "        start = text.find(search_token, cursor)\n",
    "        if start == -1:\n",
    "            continue\n",
    "            \n",
    "        end = start + len(search_token)\n",
    "        tokens_map.append({\n",
    "            \"text\": token,\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        })\n",
    "        \n",
    "        cursor = end\n",
    "        \n",
    "    return tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_studio_to_ner_data(json_data):\n",
    "    dataset = []\n",
    "    \n",
    "    for task in tqdm(json_data, desc=\"Converting with Pyvi\"):\n",
    "        if 'data' in task and 'text' in task['data']:\n",
    "            raw_text = task['data']['text']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        tokens_map = tokenize_with_pyvi_offsets(raw_text)\n",
    "        \n",
    "        labels = [\"O\"] * len(tokens_map)\n",
    "\n",
    "        if task.get('annotations'):\n",
    "            results = task['annotations'][0]['result']\n",
    "            for item in results:\n",
    "                if item['type'] == 'labels':\n",
    "                    label_name = item['value']['labels'][0]\n",
    "                    start_char = item['value']['start']\n",
    "                    end_char = item['value']['end']\n",
    "\n",
    "                    for i, token in enumerate(tokens_map):\n",
    "                        if token['start'] >= start_char and token['end'] <= end_char:\n",
    "                            if token['start'] == start_char or (i > 0 and labels[i-1] == \"O\"):\n",
    "                                labels[i] = f\"B-{label_name}\"\n",
    "                            else:\n",
    "                                labels[i] = f\"I-{label_name}\"\n",
    "                        elif token['start'] < end_char and token['end'] > start_char:\n",
    "                             if labels[i] == \"O\": # Æ¯u tiÃªn gÃ¡n náº¿u chÆ°a cÃ³ nhÃ£n\n",
    "                                labels[i] = f\"B-{label_name}\"\n",
    "        \n",
    "        sentence = [(t['text'], labels[i]) for i, t in enumerate(tokens_map)]\n",
    "        if len(sentence) > 0:\n",
    "            dataset.append(sentence)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a70fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_sentences_to_ner_format(sentences):\n",
    "    data = {\n",
    "        \"tokens\": [],\n",
    "        \"ner_tags\": []\n",
    "    }\n",
    "\n",
    "    for sent in sentences:\n",
    "        tokens = [tok for tok, lbl in sent]\n",
    "        labels = [lbl for tok, lbl in sent]\n",
    "\n",
    "        data[\"tokens\"].append(tokens)\n",
    "        data[\"ner_tags\"].append(labels)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccae88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "print(\"\\nConverting to BIO format...\")\n",
    "train_sentences = convert_label_studio_to_ner_data(train_json)\n",
    "dev_sentences   = convert_label_studio_to_ner_data(dev_json)\n",
    "test_sentences  = convert_label_studio_to_ner_data(test_json)\n",
    "\n",
    "train_data = ner_sentences_to_ner_format(train_sentences)\n",
    "dev_data   = ner_sentences_to_ner_format(dev_sentences)\n",
    "test_data  = ner_sentences_to_ner_format(test_sentences)\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(dev_data),\n",
    "    \"test\": Dataset.from_dict(test_data),\n",
    "})\n",
    "\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc342a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = set()\n",
    "\n",
    "for split in raw_datasets.keys():\n",
    "    for seq in raw_datasets[split]['ner_tags']:\n",
    "        for label in seq:\n",
    "            label_list.add(label)\n",
    "\n",
    "label_list = sorted(list(label_list)) \n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "\n",
    "print(f\"Danh sÃ¡ch nhÃ£n tÃ¬m tháº¥y ({len(label_list)}): {label_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe03879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, label2id):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        max_length=256,\n",
    "        padding=False,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    word_ids = tokenized.word_ids()\n",
    "\n",
    "    prev_word_id = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            labels.append(-100)\n",
    "        elif word_id != prev_word_id:\n",
    "            labels.append(label2id[example[\"ner_tags\"][word_id]])\n",
    "        else:\n",
    "            tag = example[\"ner_tags\"][word_id]\n",
    "            if tag.startswith(\"B-\"):\n",
    "                tag = tag.replace(\"B-\", \"I-\")\n",
    "            labels.append(label2id[tag])\n",
    "        prev_word_id = word_id\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    lambda x: tokenize_and_align_labels(x, label2id),\n",
    "    batched=False,               \n",
    "    remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(\"CÃ¡c cá»™t trong dataset:\", tokenized_datasets['train'].column_names)\n",
    "\n",
    "print(\"\\n--- KIá»‚M TRA MáºªU Táº¬P TRAIN ---\")\n",
    "print(tokenized_datasets['train'][0]['labels'])\n",
    "\n",
    "print(\"\\n--- KIá»‚M TRA MáºªU Táº¬P VALIDATION ---\")\n",
    "print(tokenized_datasets['validation'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenized_datasets['train']\n",
    "print(len(sample[\"input_ids\"]))\n",
    "print(len(sample[\"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534643e",
   "metadata": {},
   "source": [
    "## Train Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(tokenized_train, num_labels, o_label_id=None):\n",
    "    counts = Counter()\n",
    "    for ex in tokenized_train:\n",
    "        for l in ex[\"labels\"]:\n",
    "            if l == -100:\n",
    "                continue\n",
    "            counts[int(l)] += 1\n",
    "\n",
    "    freqs = np.zeros(num_labels, dtype=np.float64)\n",
    "    for i in range(num_labels):\n",
    "        freqs[i] = counts.get(i, 0)\n",
    "\n",
    "    freqs = np.clip(freqs, 1.0, None)\n",
    "\n",
    "    weights = (freqs.sum() / freqs)\n",
    "    weights = weights / weights.mean()\n",
    "\n",
    "    if o_label_id is not None:\n",
    "        weights[o_label_id] = min(weights[o_label_id], 0.5)\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        self._loss_fct = None\n",
    "        self._loss_fct_device = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_device = logits.device\n",
    "        weight = None\n",
    "        if self.class_weights is not None:\n",
    "            weight = self.class_weights.to(device=loss_device, dtype=torch.float)\n",
    "\n",
    "        if (self._loss_fct is None) or (self._loss_fct_device != loss_device):\n",
    "            self._loss_fct = nn.CrossEntropyLoss(weight=weight, ignore_index=-100)\n",
    "            self._loss_fct_device = loss_device\n",
    "\n",
    "        loss = self._loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8,\n",
    " )\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "print(\"Äang táº£i pre-trained PhoBERT...\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    " )\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"ÄÃ£ resize model embedding vá» kÃ­ch thÆ°á»›c: {len(tokenizer)}\")\n",
    "\n",
    "from transformers import EarlyStoppingCallback, set_seed\n",
    "set_seed(42)\n",
    "\n",
    "o_label_id = label2id.get(\"O\", None)\n",
    "class_weights = compute_class_weights(tokenized_datasets[\"train\"], len(label_list), o_label_id=o_label_id)\n",
    "print(\"Class weights (sample):\", class_weights[: min(10, len(class_weights))].tolist())\n",
    "if o_label_id is not None:\n",
    "    print(\"'O' label id:\", o_label_id, \"weight:\", float(class_weights[o_label_id]))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phobert-ner-results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    label_smoothing_factor=0.0,  \n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    " )\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    class_weights=class_weights.to(model.device),\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ Báº®T Äáº¦U TRAINING...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nâœ… TRAINING HOÃ€N Táº¤T!\")\n",
    "\n",
    "save_path = \"./phobert-ner-final\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4545617",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "317aad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_level_confusion(trainer, dataset, label_list):\n",
    "    preds_out = trainer.predict(dataset)\n",
    "    logits = preds_out.predictions\n",
    "    labels = preds_out.label_ids\n",
    "    preds = np.argmax(logits, axis=2)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for ps, ls in zip(preds, labels):\n",
    "        for p, l in zip(ps, ls):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            y_true.append(int(l))\n",
    "            y_pred.append(int(p))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(label_list))))\n",
    "    df = pd.DataFrame(cm, index=label_list, columns=label_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592fb61",
   "metadata": {},
   "source": [
    "## Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.abspath(\"./phobert-ner-final\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\n",
    "model.to(device)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "test_args = TrainingArguments(\n",
    "    output_dir=\"./tmp\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    do_train=False,\n",
    "    do_eval=False,\n",
    "    do_predict=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_ner = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ RUNNING TEST PHASE...\")\n",
    "\n",
    "test_predictions = trainer_ner.predict(tokenized_datasets[\"test\"])\n",
    "\n",
    "logits = test_predictions.predictions\n",
    "labels = test_predictions.label_ids\n",
    "\n",
    "preds = np.argmax(logits, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d64a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "true_preds  = []\n",
    "\n",
    "for pred_seq, label_seq in zip(preds, labels):\n",
    "    seq_labels = []\n",
    "    seq_preds  = []\n",
    "\n",
    "    for p, l in zip(pred_seq, label_seq):\n",
    "        if l == -100:\n",
    "            continue\n",
    "\n",
    "        seq_labels.append(id2label[l])\n",
    "        seq_preds.append(id2label[p])\n",
    "\n",
    "    if len(seq_labels) > 0:\n",
    "        true_labels.append(seq_labels)\n",
    "        true_preds.append(seq_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== TEST SET: ENTITY-LEVEL REPORT =====\")\n",
    "print(classification_report(true_labels, true_preds, digits=4))\n",
    "\n",
    "print(\"Overall F1:\", f1_score(true_labels, true_preds))\n",
    "print(\"Overall Accuracy:\", accuracy_score(true_labels, true_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_testset(idx, raw_datasets, trainer, id2label):\n",
    "    sample = tokenized_datasets[\"test\"][idx]\n",
    "    raw_tokens = raw_datasets[\"test\"][idx][\"tokens\"]\n",
    "\n",
    "    logits = trainer.model(\n",
    "        input_ids=torch.tensor([sample[\"input_ids\"]]).to(trainer.model.device),\n",
    "        attention_mask=torch.tensor([sample[\"attention_mask\"]]).to(trainer.model.device)\n",
    "    ).logits\n",
    "\n",
    "    preds = logits.argmax(dim=-1).squeeze().tolist()\n",
    "\n",
    "    results = []\n",
    "    for tok, pred, lab in zip(raw_tokens, preds, sample[\"labels\"]):\n",
    "        if lab == -100:\n",
    "            continue\n",
    "        results.append((tok, id2label[pred]))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322da500",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_from_testset(0, raw_datasets, trainer_ner, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner_table(idx, raw_datasets, tokenized_datasets, trainer, id2label):\n",
    "    model = trainer.model\n",
    "    model.eval()\n",
    "\n",
    "    raw_tokens = raw_datasets[\"test\"][idx][\"tokens\"]\n",
    "    true_labels = raw_datasets[\"test\"][idx][\"ner_tags\"]\n",
    "    sample = tokenized_datasets[\"test\"][idx]\n",
    "\n",
    "    input_ids = torch.tensor([sample[\"input_ids\"]]).to(model.device)\n",
    "    attention_mask = torch.tensor([sample[\"attention_mask\"]]).to(model.device)\n",
    "    labels = sample[\"labels\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "    preds = outputs.logits.argmax(dim=-1).squeeze().tolist()\n",
    "\n",
    "    rows = []\n",
    "    word_ptr = 0  \n",
    "\n",
    "    for pred_id, label_id in zip(preds, labels):\n",
    "        if label_id == -100:\n",
    "            continue\n",
    "\n",
    "        if word_ptr >= len(raw_tokens):\n",
    "            break\n",
    "\n",
    "        token = raw_tokens[word_ptr]\n",
    "        true_label = true_labels[word_ptr]\n",
    "        pred_label = id2label[pred_id]\n",
    "\n",
    "        rows.append({\n",
    "            \"Token\": token,\n",
    "            \"Thá»±c táº¿ (True)\": true_label,\n",
    "            \"Dá»± Ä‘oÃ¡n (Pred)\": pred_label,\n",
    "            \"Káº¿t quáº£\": \"âœ…\" if true_label == pred_label else \"âŒ\"\n",
    "        })\n",
    "\n",
    "        word_ptr += 1\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    correct = (df[\"Thá»±c táº¿ (True)\"] == df[\"Dá»± Ä‘oÃ¡n (Pred)\"]).sum()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\" NER PREDICTION SAMPLE\")\n",
    "    print(f\"Sentence #{idx+1}\")\n",
    "    print(f\"-> Correct Predictions: {correct} / {len(df)} tokens\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4391ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predict_ner_table(\n",
    "    idx=0,\n",
    "    raw_datasets=raw_datasets,\n",
    "    tokenized_datasets=tokenized_datasets,\n",
    "    trainer=trainer_ner,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)      \n",
    "pd.set_option(\"display.max_columns\", None)   \n",
    "pd.set_option(\"display.width\", None)        \n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
