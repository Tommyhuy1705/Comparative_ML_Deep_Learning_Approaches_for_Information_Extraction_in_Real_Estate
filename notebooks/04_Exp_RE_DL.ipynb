{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f854167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyvi transformers seqeval evaluate google-cloud-bigquery-storage protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69441aa7",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "import itertools\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict \n",
    "from transformers import AutoModel, RobertaTokenizerFast\n",
    "from transformers import AutoModelForTokenClassification, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from seqeval.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534643e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data files...\")\n",
    "TRAIN_PATH = '../data/04_model_input/train_dataset.json'\n",
    "TEST_PATH = '../data/04_model_input/test_dataset.json'\n",
    "DEV_PATH = '../data/04_model_input/dev_dataset.json'\n",
    "\n",
    "with open(TRAIN_PATH, 'r', encoding='utf-8') as f:\n",
    "    train_json = json.load(f)\n",
    "\n",
    "with open(TEST_PATH, 'r', encoding='utf-8') as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "with open(DEV_PATH, 'r', encoding='utf-8') as f:\n",
    "    dev_json = json.load(f)\n",
    "\n",
    "print(f\"-> Train raw docs: {len(train_json)}\")\n",
    "print(f\"-> Test raw docs: {len(test_json)}\")\n",
    "print(f\"-> Dev raw docs: {len(dev_json)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a7106",
   "metadata": {},
   "source": [
    "## Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    add_prefix_space=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4545617",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317aad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_re_data_from_json(json_data):\n",
    "    dataset = []\n",
    "    for task in json_data:\n",
    "        text = task['data']['text']\n",
    "        entities = {}\n",
    "        relations = []\n",
    "        if not task['annotations']:\n",
    "            continue\n",
    "            \n",
    "        for item in task['annotations'][0]['result']:\n",
    "            if item['type'] == 'labels':\n",
    "                entities[item['id']] = {\n",
    "                    'id': item['id'],\n",
    "                    'text': item['value']['text'],\n",
    "                    'start': item['value']['start'],\n",
    "                    'end': item['value']['end'],\n",
    "                    'label': item['value']['labels'][0]\n",
    "                }\n",
    "            elif item['type'] == 'relation':\n",
    "                if 'labels' not in item or not item['labels']:\n",
    "                    continue\n",
    "                relations.append({\n",
    "                    'from': item['from_id'],\n",
    "                    'to': item['to_id'],\n",
    "                    'label': item['labels'][0]\n",
    "                })\n",
    "\n",
    "        true_relation_map = {}\n",
    "        for rel in relations:\n",
    "            true_relation_map[(rel['from'], rel['to'])] = rel['label']\n",
    "            \n",
    "        entity_ids = list(entities.keys())\n",
    "        for id1, id2 in itertools.permutations(entity_ids, 2):\n",
    "            e1 = entities[id1]\n",
    "            e2 = entities[id2]\n",
    "\n",
    "            label = true_relation_map.get((id1, id2), 'NO_RELATION')\n",
    "            \n",
    "            dataset.append({\n",
    "                'text': text,\n",
    "                'ent1': e1,\n",
    "                'ent2': e2,\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_entity_markers(text, ent1, ent2):\n",
    "    ents = sorted([ent1, ent2], key=lambda x: x[\"start\"], reverse=True)\n",
    "\n",
    "    for i, ent in enumerate(ents):\n",
    "        if i == 0:\n",
    "            start_tag, end_tag = \"[E2]\", \"[/E2]\"\n",
    "        else:\n",
    "            start_tag, end_tag = \"[E1]\", \"[/E1]\"\n",
    "\n",
    "        text = (\n",
    "            text[:ent[\"start\"]] +\n",
    "            f\"{start_tag} \" +\n",
    "            text[ent[\"start\"]:ent[\"end\"]] +\n",
    "            f\" {end_tag}\" +\n",
    "            text[ent[\"end\"]:]\n",
    "        )\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97402aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_re_samples(json_data):\n",
    "    samples = prepare_re_data_from_json(json_data)\n",
    "    processed = []\n",
    "\n",
    "    for s in samples:\n",
    "        marked_text = insert_entity_markers(\n",
    "            s[\"text\"], s[\"ent1\"], s[\"ent2\"]\n",
    "        )\n",
    "\n",
    "        processed.append({\n",
    "            \"text\": marked_text,\n",
    "            \"label\": s[\"label\"]\n",
    "        })\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd335b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConverting to RE format...\")\n",
    "\n",
    "raw_datasets_re = DatasetDict({\n",
    "    \"train\": Dataset.from_list(build_re_samples(train_json)),\n",
    "    \"validation\": Dataset.from_list(build_re_samples(dev_json)),\n",
    "    \"test\": Dataset.from_list(build_re_samples(test_json)),\n",
    "})\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- KI·ªÇM TRA M·∫™U T·∫¨P TRAIN ---\")\n",
    "print(raw_datasets_re['train'][0]['text'])\n",
    "print(raw_datasets_re['train'][0]['label'])\n",
    "\n",
    "\n",
    "print(\"\\n--- KI·ªÇM TRA M·∫™U T·∫¨P VALIDATION ---\")\n",
    "print(raw_datasets_re['validation'][0]['text'])\n",
    "print(raw_datasets_re['validation'][0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfca722",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_label_set = set()\n",
    "for split in raw_datasets_re.keys():\n",
    "    for lbl in raw_datasets_re[split][\"label\"]:\n",
    "        re_label_set.add(lbl)\n",
    "\n",
    "re_label_list = sorted(list(re_label_set))\n",
    "re_label2id = {l: i for i, l in enumerate(re_label_list)}\n",
    "re_id2label = {i: l for l, i in re_label2id.items()}\n",
    "\n",
    "print(\"RE labels:\", re_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_re_label(example):\n",
    "    example[\"labels\"] = re_label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "raw_datasets_re = raw_datasets_re.map(encode_re_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens([\"[E1]\", \"[/E1]\", \"[E2]\", \"[/E2]\"])\n",
    "\n",
    "def tokenize_re(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized_datasets_re = raw_datasets_re.map(\n",
    "    tokenize_re,\n",
    "    batched=False,\n",
    "    remove_columns = ['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_datasets_re[\"train\"].column_names)\n",
    "print(tokenized_datasets_re[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170083fe",
   "metadata": {},
   "source": [
    "## Train Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights_re(dataset, num_labels):\n",
    "    counts = Counter(int(x[\"labels\"]) for x in dataset)\n",
    "    freqs = np.array([counts.get(i, 1) for i in range(num_labels)], dtype=np.float64)\n",
    "    weights = freqs.sum() / freqs\n",
    "    weights = weights / weights.mean()\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainerRE(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        self._loss_fct = None\n",
    "        self._loss_fct_device = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        device = logits.device\n",
    "        weight = self.class_weights.to(device) if self.class_weights is not None else None\n",
    "\n",
    "        if self._loss_fct is None or self._loss_fct_device != device:\n",
    "            self._loss_fct = nn.CrossEntropyLoss(weight=weight)\n",
    "            self._loss_fct_device = device\n",
    "\n",
    "        loss = self._loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07517c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_re = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    num_labels=len(re_label_list),\n",
    "    id2label=re_id2label,\n",
    "    label2id=re_label2id\n",
    ")\n",
    "\n",
    "model_re.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_re_ignore_no_relation(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    valid_idx = labels != re_label2id[\"NO_RELATION\"]\n",
    "    labels = labels[valid_idx]\n",
    "    preds = preds[valid_idx]\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"macro_f1_no_relation\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_re = TrainingArguments(\n",
    "    output_dir=\"./phobert-re-results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=2165,\n",
    "    save_steps=2165,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1_no_relation\",\n",
    "    greater_is_better=True,\n",
    "    label_smoothing_factor=0.0,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_re = compute_class_weights_re(tokenized_datasets_re[\"train\"], len(re_label_list))\n",
    "\n",
    "trainer_re = WeightedTrainerRE(\n",
    "    model=model_re,\n",
    "    args=training_args_re,\n",
    "    train_dataset=tokenized_datasets_re[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_re[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics_re_ignore_no_relation,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    class_weights=class_weights_re,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ B·∫ÆT ƒê·∫¶U TRAINING...\")\n",
    "trainer_re.train()\n",
    "\n",
    "print(\"\\n‚úÖ TRAINING HO√ÄN T·∫§T!\")\n",
    "\n",
    "save_path = \"./phobert-re-final\"\n",
    "trainer_re.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef457d7",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_level_confusion(trainer, dataset, label_list):\n",
    "    preds_out = trainer.predict(dataset)\n",
    "    logits = preds_out.predictions\n",
    "    labels = preds_out.label_ids\n",
    "    preds = np.argmax(logits, axis=2)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for ps, ls in zip(preds, labels):\n",
    "        for p, l in zip(ps, ls):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            y_true.append(int(l))\n",
    "            y_pred.append(int(p))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(label_list))))\n",
    "    df = pd.DataFrame(cm, index=label_list, columns=label_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d85117",
   "metadata": {},
   "source": [
    "## Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d51097",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.abspath(\"./phobert-re-final\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "model.to(device)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "label_list = list(id2label.values())\n",
    "\n",
    "print(\"Labels:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenized_datasets_re['test']\n",
    "tokenized_test.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"labels\", \"input_ids\", \"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./tmp\",\n",
    "    per_device_eval_batch_size=64,   \n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer_re = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "pred_output = trainer_re.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = pred_output.predictions\n",
    "y_true = pred_output.label_ids\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "\n",
    "no_rel_id = label2id[\"NO_RELATION\"]\n",
    "\n",
    "mask = y_true != no_rel_id\n",
    "y_true_filt = y_true[mask]\n",
    "y_pred_filt = y_pred[mask]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_filt,\n",
    "    y_pred_filt,\n",
    "    average=\"macro\",\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "    y_true_filt,\n",
    "    y_pred_filt,\n",
    "    average=\"micro\",\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "accuracy = accuracy_score( y_true_filt, y_pred_filt)\n",
    "\n",
    "print(\"\\n===== RE TEST RESULTS =====\")\n",
    "print(f\"Macro F1 (no NO_RELATION): {f1:.4f}\")\n",
    "print(f\"Macro Precision:          {precision:.4f}\")\n",
    "print(f\"Macro Recall:             {recall:.4f}\")\n",
    "print(f\"Micro F1:                 {micro_f1:.4f}\")\n",
    "print(f\"Accuracy:                 {accuracy:.4f}\")\n",
    "\n",
    "labels_no_rel_ids = [\n",
    "    label2id[l] for l in label_list if l != \"NO_RELATION\"\n",
    "]\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    y_true_filt,\n",
    "    y_pred_filt,\n",
    "    labels=labels_no_rel_ids\n",
    ")\n",
    "\n",
    "labels_no_rel = [id2label[i] for i in labels_no_rel_ids]\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=labels_no_rel,\n",
    "    columns=labels_no_rel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
